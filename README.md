# EdenMed Segmentation Challenge

# Informe

Las siguientes secciones incluyen la guÃ­a paso a paso de cÃ³mo se ha resuelto el challenge.

## Data exploration

En la base de datos suministrada hay 3 tablas:

> Table: study_patient_data
>  Columns: study_id, body_parts, modalities, patient_age, patient_gender
> Rows: 549

Contiene informaciÃ³n sobre el estudio en particular (tipo de modalidad, secciÃ³n estudiada, datos del paciente).

> Table: study_instances
>  Columns: study_id, instance_id, measurement_data, file_name
>  Rows: 460

Para cada estudio, contiene una serie de datos de mediciÃ³n e imÃ¡genes asosciadas.
Nota: para cada `study_id` se encontrÃ³ un Ãºnico `file_name` asosciado.

> Table: study_report
>  Columns: study_id, report_id, report_value
>  Rows: 555
>

Para cada estudio, contiene un reporte en HTML escrito en lenguaje natural espaÃ±ol.

![Tablas presentes en la base de datos](./nbs-images/tables.png)

**Otras Observaciones:**
- `study_patient_data` contiene una Ãºnica fila por `study_id`.
- `study_instances` contiene varias instancias por `study_id`, pero una Ãºnica imagen respectiva `file_name`.
- `study_id` contiene varios reportes por `study_id`.
- Existen `sutdy_id` que no tienen imÃ¡genes asosciadas (esto se desprende simplemente de ver la cantidad de filas).
- Existen `file_name` para los cuales no existe una imagen jpeg respectiva.

Todas  estas observaciones pueden corroborarse ejecutando `python db.py` que correrÃ¡ estos chequeos.

### ExploraciÃ³n de caracterÃ­sticas demogrÃ¡ficas de los pacientes

Se ha calculado:
- La composiciÃ³n de los estudios por sexo.
- La composiciÃ³n de los estudios por edad del paciente.
- La composiciÃ³n de los estudios por modalidad (CT, CX, DT, DX).
- La distribuciÃ³n de los CTR.
**Nota**: el cÃ³digo que genera los grÃ¡ficos estÃ¡ en la notebook: `notebook.ipynb`

![ComposiciÃ³n de los estudios por sexo.](./nbs-images/sex_composition.png)

![ComposiciÃ³n de los estudios por edad.](./nbs-images/age.png)
![ComposiciÃ³n de los estudios por modalidad.](./nbs-images/modalities_composition.png)
![DistribuciÃ³n CTR](./nbs-images/ctr.png)

### Propuesta para el anÃ¡lisis de los reportes mÃ©dicos

Para el anÃ¡lisis de los reportes mÃ©dicos se propone generar una ontologÃ­a para cada reporte.
Por ejemplo el reporte:

````{verbatim}
La arteria pulmonar de 16mm. (normal hasta 17mm).La regiÃ³n parahiliar sin ensanchamientos que sugieran alteraciones. El mediastino superior de aspecto normal. La silueta cardiaca con eje aparentemente normal, de perfiles y contornos conservados con un Ã­ndice cardiotorÃ¡cico de .42 (normal hasta .5) Las estructuras vasculares, vena cava superior, aorta y arterias pulmonares sin alteraciones.
````

GenerarÃ­a la siguiente ontologÃ­a:
```
arteria_pulmonar.mm = 16
region_parahiliar.ensanchamientos = False
mediastino_superior.normal = True
silueta_cardiaca.normal = True
indice_cardiotoracico = 0.42
estructuras_vasculares.alteraciones = False
vena_cava_superior.alteraciones = False
aorta.alteraciones = False
arterias pulmonares.alteraciones = False
```

El prompt para generar dichas ontologÃ­as se encuentra en `ontology.py`

## ConstrucciÃ³n del dataset

#### Unificando las tablas

Tener 3 tablas normalizadas es Ãºtil para el funcionamiento de un sistema transaccional. Pero a la hora de operar con datos de forma analÃ­tica lo mejor es tener toda la informaciÃ³n en **una sÃ³la tabla** (por mÃ¡s que no estÃ© normalizada). Para ello se:
1. AgrupÃ³ por `study_id` las tablas `study_instances` y `study_report`. Las columnas se agregaron como listas de valores.
2. Se hizo un merge (JOIN de tablas) por `study_id`.
3. Se eliminaron filas que no contenÃ­an un `file_name` o para el cuÃ¡l no existÃ­an imÃ¡genes asosciadas.

Esto se encuentra en la funciÃ³n `db.create_dataset`:

#### Seleccionando las imÃ¡genes de tÃ³rax

Ahora debemos seleccionar las imÃ¡genes que correspondan efectivamente a torax. Analizando los `body_parts` vemos los siguientes valores:

> {'TÃ“RAX', 'L SPINE', 'TORAX TORAX LATERAL', 'COLUMNA', 'BREAST', 'DEFAULT', 'LSPINE', 'SHOULDER', 'COLUMNA COLUMNA-L/S LATERAL', 'Pectoral', 'COL. LUMBAR', 'CSPINE', 'TORAX', 'PELVIS', 'TORAX TORAX PA', 'Senos Paranasales', 'NECK', 'THORAX', 'SPINE LUMBAR', 'PNS', 'L-SPINE', 'ABDOMEN', 'CHEST', 'OTHER', 'L/S-SPINE', 'HEAD', 'COLUMNA COLUMNA-L/S AP', 'ANGIO'}

Para seleccionar vamos a realizar los siguientes pasos:
1. Una primera selecciÃ³n naive, basada en `body_parts` razonables, para separarlos en clases `torax` y `not_torax`.
2. Limpiar a manualmente cada una de las dos carpetas. Para eso:
a. Viendo las miniaturas de las imÃ¡genes en `torax` seleccionamos las que no sean de torax y las movemos a la carpeta `not_torax_cleaned`.
b. Viendo las miniaturas de las imÃ¡genes en `not_torax` seleccionamos las que SI sean de torax y las movemos a la carpeta `torax_cleaned`.
c. Finalmente copiamos los archivos restantes en `not_torax` y `torax` a `torax_cleaned` y `not_torax_cleaned`.
**Observacion**: podemos hacer un limpiado a mano rÃ¡pidamente viendo las imÃ¡genes como minuaturas por dos razones. En primer lugar nuestras clases son fÃ¡cilmente identificables (podemos hacerlo viendo la miniatura). En segundo lugar, tenemos pocas imÃ¡genes (alrededor de 300).
Luego de este paso estaremos en condiciones de **entrenar un clasificador binario** lo que nos permitirÃ¡ tener una selecciÃ³n mÃ¡s precisa para imÃ¡genes futuras (para las cuales, ademÃ¡s, podemos no tener datos como `body_part`).
3. Pondremos estas dos clases en la carpeta `binary_dataset` y entranaremos un clasificador binario basado en `Resnet`.

El modelo de selecciÃ³n de tÃ³rax quedÃ³ guardado en `models/torax_detector_model.pth` y puede ser usado en una imagen de la siguiente manera:
```
python torax_detection.py --image data/test_classifier/a.jpg --model models/torax_detector_model.pth
```
Output (clase y probabildiad respectiva):
> torax 0.84

Ejemplos de imÃ¡genes de internet clasificadas:

![ImÃ¡genes de internet clasificadas por el clasificador entrenado](./nbs-images/classifier_results.png)

## Segementando pulmones

Para la segmentaciÃ³n pulmonar se ha utilizado una arquitectura U-Net (ver ApÃ©ndice II: Referencias).
La misma ha sido entrenada con **Montgomery** y **Shenzhen** datasets de readiografÃ­as de torax (ver ApÃ©ndice I: Datasets).
El cÃ³digo que se ha utilizado es el de [Repositorio de segmentaciÃ³n pulmonar (GitHub)](https://github.com/IlliaOvcharenko/lung-segmentation).

Un ejemplo de una imÃ¡gen del dataset superpuesta con la mÃ¡scara generada por el modelo:

![Ejemplo de imÃ¡gen superpuesta por su mÃ¡scara de segmentaciÃ³n.](./nbs-images/segmentation_example.png)

Se puede utilizar el modelo de segmentaciÃ³n en una imÃ¡gen con el comando:
```
python segmentation.py --image data/test_classifier/a.jpg --model models/unet-6v.pt --out mask.jpg
```

El comando anterior generarÃ¡ una imagen blanco y negro con la mÃ¡scara en el path que se le indique en el argumento --out

![ComposiciÃ³n de los estudios por modalidad.](./nbs-images/output_mask.png)

Las imÃ¡genes de `data/binary_classifier/torax` se han procesado con el segmentador y guardado en `data/binary_classifier_torax_mask`

### Por quÃ© elegimos esta implementaciÃ³n?

La razÃ³n de por quÃ© elegimos [este repositorio](https://github.com/IlliaOvcharenko/lung-segmentation) es porque ya proveÃ­a los pesos del modelo entrenado en un dataset conocido. **Y mÃ¡s importante aÃºn posee:**
- El cÃ³digo de entrenamiento mediante el cual podemos verificar que ha sido entrenado correctamente (con splits de train, validaciÃ³n y test).
- Los splits (`splits.pk`) que nos permite replicar el entrenamiento realizado.


# ApÃ©ndice I: Datasets

**Montgomery Dataset**  
- **Origen:** Montgomery County, Maryland, USA  
- **NÃºmero de imÃ¡genes:** ~138  

**Shenzhen Dataset**  
- **Origen:** Hospital NÂº3 de Shenzhen, China  
- **NÃºmero de imÃ¡genes:** ~662

Ambos datasets se encuentran en el siguiente [archivo](https://drive.google.com/file/d/1ffbbyoPf-I3Y0iGbBahXpWqYdGd7xxQQ/view). El directorio `images` contiene las radiografÃ­as y `masks` el source of truth de las mÃ¡scaras. Las mÃ¡scaras tienen el mismo nombre que su respectiva imÃ¡gen y se le ha adicionado el sufijo `_mask`. Los archivos del Shenzhen Dataset comienzan con `CHNCXR`.

```
ğŸ“ dataset/
â”œâ”€â”€ ğŸ“ images/
â”‚   â”œâ”€â”€ CHNCXR_0001_0.png  
â”‚   â”œâ”€â”€ CHNCXR_0002_0.png  
â”‚   â”œâ”€â”€ ...  (662 archivos)
â”‚   â”œâ”€â”€ MCUCXR_0001_0.png    
â”‚   â””â”€â”€ ...  (138 archivos)
â””â”€â”€ ğŸ“ mask/
    â”œâ”€â”€ CHNCXR_0001_0_mask.png  
    â”œâ”€â”€ CHNCXR_0002_0_mask.png  
    â”œâ”€â”€ ...  (662 archivos)
    â”œâ”€â”€ MCUCXR_0001_0_mask.png  
    â””â”€â”€ ...  (138 archivos)
```

# ApÃ©ndice II: Referencias

Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. *In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)* (pp. 234â€“241). Springer. https://doi.org/10.1007/978-3-319-24574-4_28
